\section{Consider an infinite series of random variables
\texorpdfstring{$X_i$}{Xi}, where each variable is generated from its
predecessor according to
\texorpdfstring{$X_i = aX_{i-1} + B_i$}{Xi = aXi-1 + Bi}.
Here \texorpdfstring{$a$}{a} is a constant and \texorpdfstring{$B_i$}{Bi}
is a Gaussian random variable with mean \texorpdfstring{$m$}{m}
and standard deviation \texorpdfstring{$s$}{s}.
If all of the \texorpdfstring{$X_i$}{Xi} are identically distributed
with mean \texorpdfstring{$\mu$}{mu} and standard deviation
\texorpdfstring{$\sigma$}{sigma}, then what constraints does this place on
\texorpdfstring{$a$}{a}, \texorpdfstring{$m$}{m}, and \texorpdfstring{$s$}{s}?
What condition will result in the \texorpdfstring{$X_i$}{Xi} also being
independent from each other? In the case that they are identically
distributed but not necessarily independent,
derive a formula for the correlation coefficient between
\texorpdfstring{$X_i$}{Xi} and \texorpdfstring{$X_{i-j}$}{Xi-j}.}

First recall a few things:
\begin{itemize}
    \item the definition of correlation coefficient: $\rho_{A,B} = \frac{\operatorname{Cov}(A,B)}{\sigma_A \sigma_B}$
    \item How does scaling affect the mean? $\overline{aX} = a\overline{X}$
    \item How does scaling affect Variance?
    
    $\operatorname{Var}(aX) = \overline{(aX)^2} - (\overline{aX})^2 = a^2\left(\overline{X^2} - (\overline{X})^2\right) = a^2\operatorname{Var}(X) $
    
    \item How does scaling affect Covariance?
    
    $\operatorname{Cov}(aX, Y) = \overline{aXY} - \overline{aX}\bar{Y} = a(\overline{XY} - \bar{X}\bar{Y}) = a\operatorname{Cov}(X,Y) $

    \item For independent Gaussians, their sum is also a Gaussian, with mean $\mu_{A + B} = \mu_A + \mu_B$ and variance $\sigma_{A+B}^2 =\sigma_A^2 + \sigma_B^2$. 
\end{itemize}

And find a relationship between $X_i$ and $X_{i-j}$:
    
\begin{align*}
    X_i &= aX_{i-1} + B_i \\
    &= a(aX_{i-2} + B_{i-1}) + B_i \\
    &= a^2X_{i-2} + aB_{i-1} + B_i \\
    &= a^3X_{i-3} + a^2B_{i-2} + aB_{i-1} + B_i \\
    &= a^4X_{i-4} + a^3B_{i-3} + a^2B_{i-2} + a^1B_{i-1} + a^0B_{i-0} \\
    & \vdots \\
    X_i &= a^jX_{i-j} + \sum_{k=0}^{j-1}a^kB_{i-k} \\
\end{align*}

\begin{itemize}
    \item How are $a,m,s$ constrained?
    
    For the sum and variance of infinitely many $B_i$ to be not-infinite for non-zero $m,s$, we need $a \in (-1,1)$.

    From the linearity of means, $\mu = a\mu + m$.

    And since $X_{i-1}, B_i$ are independent, $\sigma^2 = a^2\sigma^2 + s^2$.

    \item What's the condition such that the $X_i$ are independent from each other?

    Well if $a=0$ then $X_i = B_i$, just a Gaussian, and I think we can assume all the $B_i$ are independent even though the question doesn't specifically say so. 

    \item Find $\rho_{X_i,X_{i-j}}$ if $X_i,X_{i-j}$ are not independent.

    Consider the following:
    \begin{align*}
        \operatorname{Cov}((A+B), C) &= \overline{(A+B)C} - \overline{A+B}\overline{C} \\
        &= \overline{AC} + \overline{BC} - (\bar{A}+\bar{B})\bar{C} \\
        &= \overline{AC} - \bar{A}\bar{C} + \overline{BC} -\bar{B}\bar{C} \\
        &= \operatorname{Cov}(A,C) + \operatorname{Cov}(B,C) \\
    \end{align*}

    If we apply this to our expression for $X_i, X_{i-j}$
    \begin{align*}
        \operatorname{Cov}(X_i, X_{i-j}) &= \operatorname{Cov}(a^jX_{i-j} + \sum_{k=0}^{j-1}a^kB_{i-k}, X_{i-j}) \\
        &= \operatorname{Cov}(a^jX_{i-j}, X_{i-j}) + \operatorname{Cov}(\sum_{k=0}^{j-1}a^kB_{i-k}, X_{i-j}) \\
        &= a_j\operatorname{Var}(X_{i-j}) + \operatorname{Cov}(\sum_{k=0}^{j-1}a^kB_{i-k}, X_{i-j}) \\
        &= a_j\sigma^2 + \operatorname{Cov}(\sum_{k=0}^{j-1}a^kB_{i-k}, X_{i-j}) \\
    \end{align*}

    The $B_{i-k}$ are independent of $X_{i-j}$ (since $k < j$ and $X_{i-j}$ only depends on $B$s with a lower index), so the last part vanishes.

    \begin{align*}
        \operatorname{Cov}(X_i, X_{i-j}) &= a^j \sigma^2 \\
    \end{align*}

    \begin{align*}
        \rho_{X_i,X_{i-j}} &= \frac{\operatorname{Cov}(X_i,X_{i-j})}{\sigma_{X_i} \sigma_{X_{i-j}}} \\
        &= \frac{\sigma^2 a^{j}}{\sigma^2} \\
        &= a^{j} \\
    \end{align*}

\end{itemize}